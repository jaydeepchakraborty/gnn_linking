{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GenCombSim.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMAj+D1q/x9x3UKLpZHGD7/"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wtSc7Yn0CiJS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617588733396,"user_tz":420,"elapsed":21164,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}},"outputId":"a1944137-887d-40a4-dd0b-6b1f35867c10"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","DIR='/content/drive/MyDrive/Research/OntoConnectWithGNN/GNN_1/Anatomy/'\n","\n","import os\n","os.chdir(DIR)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"kXfNEpgiE4g1","executionInfo":{"status":"ok","timestamp":1617588796791,"user_tz":420,"elapsed":84547,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}},"outputId":"ec638dfc-71ed-44b6-eece-a79827d40186"},"source":["from IPython.display import Javascript  # Restrict height of output cell.\n","display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))\n","\n","!python -c \"import torch; print(torch.__version__)\"\n","!python -c \"import torch; print(torch.version.cuda)\"\n","\n","!pip install git+https://github.com/facebookresearch/fastText.git\n","!pip install git+https://github.com/facebookresearch/PyTorch-BigGraph.git"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"application/javascript":["google.colab.output.setIframeHeight(0, true, {maxHeight: 100})"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["1.8.1+cu101\n","10.1\n","Collecting git+https://github.com/facebookresearch/fastText.git\n","  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-6yi63gxv\n","  Running command git clone -q https://github.com/facebookresearch/fastText.git /tmp/pip-req-build-6yi63gxv\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (2.6.2)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (54.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.19.5)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3090363 sha256=b99f0740289f600a60e7857763639b82e966c628987ffd6c023c39d313ea2f43\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-t_8dzm5s/wheels/69/f8/19/7f0ab407c078795bc9f86e1f6381349254f86fd7d229902355\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","Successfully installed fasttext-0.9.2\n","Collecting git+https://github.com/facebookresearch/PyTorch-BigGraph.git\n","  Cloning https://github.com/facebookresearch/PyTorch-BigGraph.git to /tmp/pip-req-build-l10dyqpx\n","  Running command git clone -q https://github.com/facebookresearch/PyTorch-BigGraph.git /tmp/pip-req-build-l10dyqpx\n","Requirement already satisfied: attrs>=18.2 in /usr/local/lib/python3.7/dist-packages (from torchbiggraph==1.0.1.dev0) (20.3.0)\n","Requirement already satisfied: h5py>=2.8 in /usr/local/lib/python3.7/dist-packages (from torchbiggraph==1.0.1.dev0) (2.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchbiggraph==1.0.1.dev0) (1.19.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from torchbiggraph==1.0.1.dev0) (54.2.0)\n","Requirement already satisfied: torch>=1 in /usr/local/lib/python3.7/dist-packages (from torchbiggraph==1.0.1.dev0) (1.8.1+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchbiggraph==1.0.1.dev0) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py>=2.8->torchbiggraph==1.0.1.dev0) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1->torchbiggraph==1.0.1.dev0) (3.7.4.3)\n","Building wheels for collected packages: torchbiggraph\n","  Building wheel for torchbiggraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchbiggraph: filename=torchbiggraph-1.0.1.dev0-cp37-none-any.whl size=119004 sha256=8cf79e40098e4516d3594b58b740afbaa567726e0ee32b4486427bd6dc593c71\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-a3vu1xjz/wheels/d5/d0/e8/9fa5ee999e79534d0c4cb2c9127e08cbf42ba9f1e701158a33\n","Successfully built torchbiggraph\n","Installing collected packages: torchbiggraph\n","Successfully installed torchbiggraph-1.0.1.dev0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7d6p6HOwW1xs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617588799979,"user_tz":420,"elapsed":87724,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}},"outputId":"c3b7af76-faac-466d-e8a9-8154d1c43a97"},"source":["#from OntoSimImports import *\n","%run OntoSimImports.py"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ayWtqe7gW17t","executionInfo":{"status":"ok","timestamp":1617588801158,"user_tz":420,"elapsed":88895,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}}},"source":["#import OntoSimConstants\n","%run OntoSimConstants.py\n","from OntoSimConstants import *"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"vWq9XkeLWu7U","executionInfo":{"status":"ok","timestamp":1617588801163,"user_tz":420,"elapsed":88894,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}}},"source":["def assignVar():\n","    conf = {\n","        'ws_fl_nm': DATA_DIR+'output/',\n","        'op_fl': DATA_DIR+'/output/output_final.json'\n","    }\n","\n","    return conf"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YaPYG6nyWtbs","executionInfo":{"status":"ok","timestamp":1617588801164,"user_tz":420,"elapsed":88889,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}}},"source":["def loadData(fl):\n","    with open(code_path + fl) as f:\n","        data = json.load(f)\n","\n","    return data"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"8sn25BW2WrDx","executionInfo":{"status":"ok","timestamp":1617588801164,"user_tz":420,"elapsed":88883,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}}},"source":["def modifyWsMs(word_sim_lst, meta_sim_lst):\n","    word_sim_lst_modf = copy.deepcopy(word_sim_lst)\n","    meta_sim_lst_modf = copy.deepcopy(meta_sim_lst)\n","\n","    word_sim_arr = [item[1] for item in word_sim_lst_modf]  # only similarity values\n","    meta_sim_arr = [item[1] for item in meta_sim_lst_modf]  # only similarity values\n","\n","    word_sim_sd = statistics.stdev(word_sim_arr)\n","    meta_sim_sd = statistics.stdev(meta_sim_arr)\n","\n","    k = 0.0\n","\n","    if (word_sim_sd == 0 or meta_sim_sd == 0):\n","        return word_sim_lst_modf, meta_sim_lst_modf\n","\n","    k = meta_sim_sd / word_sim_sd\n","\n","    # print(\"K: \"+str(k))\n","\n","    if(k>1): # meta-sim is more spread than word-sim, reducing the spread of meta-info\n","        for idx, _ in enumerate(meta_sim_lst_modf):\n","            meta_sim_lst_modf[idx][1] = float(meta_sim_lst_modf[idx][1]) / k\n","    else: # word-sim is more spread than meta-sim, increasing the spread of meta-info\n","        for idx, _ in enumerate(word_sim_lst_modf):\n","            word_sim_lst_modf[idx][1] = float(word_sim_lst_modf[idx][1]) * k\n","\n","\n","    max_word_sim = 0\n","    max_meta_sim = 0\n","    for idx, _ in enumerate(meta_sim_lst_modf):\n","        if(meta_sim_lst_modf[idx][1] > max_meta_sim):\n","            max_meta_sim = meta_sim_lst_modf[idx][1]\n","    for idx, _ in enumerate(word_sim_lst_modf):\n","        if(word_sim_lst_modf[idx][1]>max_word_sim):\n","            max_word_sim = word_sim_lst_modf[idx][1]\n","\n","    pow_word_sim = math.floor(math.log(max_word_sim))\n","    pow_meta_sim = math.floor(math.log(max_meta_sim))\n","    if(pow_word_sim>pow_meta_sim):\n","        pow_val = pow_word_sim - pow_meta_sim\n","        for idx, _ in enumerate(meta_sim_lst_modf):\n","            meta_sim_lst_modf[idx][1] = float(meta_sim_lst_modf[idx][1]) * pow(10, pow_val)\n","    else:\n","        pow_val = pow_meta_sim - pow_word_sim\n","        for idx, _ in enumerate(word_sim_lst_modf):\n","            word_sim_lst_modf[idx][1] = float(word_sim_lst_modf[idx][1]) * pow(10, pow_val)\n","\n","    return word_sim_lst_modf, meta_sim_lst_modf"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"hl_3NG97S0Tx","executionInfo":{"status":"ok","timestamp":1617588801165,"user_tz":420,"elapsed":88878,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}}},"source":["def saveFinalOP(final_op, conf, db_param):\n","  with open(code_path+db_param['op_fl'], 'w') as outfile:\n","    json.dump(final_op, outfile, indent=4)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"CsDM2FdphsOC","executionInfo":{"status":"ok","timestamp":1617588801165,"user_tz":420,"elapsed":88871,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}}},"source":["# meta similarity\n","def ontoEvalMS(dist_ind, db_param):\n","\n","    try:\n","        print(\"#################### OntoEvaluation START ####################\")\n","\n","        conf = assignVar()\n","\n","        word_sim_info = None\n","        meta_sim_info = None\n","        if (dist_ind == word_sim_ind_1):  # word_sim_ind_1 = \"cosine\"\n","            word_sim_info = loadData(conf[\"ws_fl_nm\"] + \"word_sim/word_sim_cosine.json\")\n","            meta_sim_info = loadData(conf[\"ws_fl_nm\"] + \"meta_sim/meta_sim_cosine.json\")\n","        elif (dist_ind == word_sim_ind_2):  # word_sim_ind_2 = \"euclidean\"\n","            word_sim_info = loadData(conf[\"ws_fl_nm\"] + \"word_sim/word_sim_euclidean.json\")\n","            meta_sim_info = loadData(conf[\"ws_fl_nm\"] + \"meta_sim/meta_sim_euclidean.json\")\n","\n","\n","        word_wt = 0.5\n","        meta_wt = 0.5\n","        threshold = 0.0\n","        if (db_param[\"db_nm\"] == ds_nm_1):\n","            word_wt = db_param[\"word_wt_ds\"]\n","            meta_wt = db_param[\"meta_wt_ds\"]\n","            threshold = db_param[\"threshold_ds\"]\n","\n","        final_op = []\n","        for trgt_key in word_sim_info:\n","\n","            word_sim_lst = [[key, sim] for key, sim in word_sim_info[trgt_key].items()]\n","            meta_sim_lst = [[key, sim] for key, sim in meta_sim_info[trgt_key].items()]\n","\n","            word_sim_lst_modf, meta_sim_lst_modf = modifyWsMs(word_sim_lst, meta_sim_lst)\n","            pred_sim_lst = []\n","            for idx, word_sim in enumerate(word_sim_lst_modf):\n","                word_sim_key, word_sim_val = word_sim[0], word_sim[1]\n","                for m_key, m_val in meta_sim_lst_modf:\n","                    if(m_key == word_sim_key):\n","                        new_sim_val = word_wt * word_sim_val + meta_wt * m_val\n","                        pred_sim_lst.append([word_sim_key, new_sim_val])\n","\n","\n","            pred_sim_sort = sorted(pred_sim_lst, key=lambda x: x[1], reverse=False)\n","\n","            pred_final_op_lst = []\n","            for val, msr in pred_sim_sort:\n","                if(msr<threshold and len(pred_final_op_lst)<db_param[\"op_k\"]):\n","                    pred_final_op_lst.append(val)\n","\n","            join_str=join_str_cnst\n","            if(len(pred_final_op_lst)>0):\n","                tmp_op = {\"entity1\": \"\", \"entity2\": \"\", \"measure\": \"\"}\n","                tmp_op['entity1'] = trgt_key\n","                tmp_op['entity2'] = join_str.join(pred_final_op_lst)\n","                tmp_op['measure'] = 1.0\n","                final_op.append(tmp_op)\n","\n","        saveFinalOP(final_op, conf, db_param)\n","        time.sleep(wait_time)\n","\n","    except Exception as exp:\n","        raise exp\n","    finally:\n","        print(\"#################### OntoEvaluation FINISH ####################\")"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzqGgInCjCd6","executionInfo":{"status":"ok","timestamp":1617588801166,"user_tz":420,"elapsed":88866,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}}},"source":["# word similarity\n","def ontoEvalWS(dist_ind, db_param):\n","\n","    try:\n","        print(\"#################### OntoEvaluation START ####################\")\n","\n","        conf = assignVar()\n","\n","        word_sim_info = None\n","        if (dist_ind == word_sim_ind_1):  # word_sim_ind_1 = \"cosine\"\n","            word_sim_info = loadData(conf[\"ws_fl_nm\"] + \"word_sim/word_sim_cosine.json\")\n","        elif (dist_ind == word_sim_ind_2):  # word_sim_ind_2 = \"euclidean\"\n","            word_sim_info = loadData(conf[\"ws_fl_nm\"] + \"word_sim/word_sim_euclidean.json\")\n","\n","\n","        threshold = 0.0\n","        if (db_param[\"db_nm\"] == ds_nm_1):\n","            threshold = db_param[\"threshold_ds\"]\n","\n","        final_op = []\n","        for trgt_key in word_sim_info:\n","\n","            word_sim_lst = [[key, sim] for key, sim in word_sim_info[trgt_key].items()]\n","            pred_sim_lst = word_sim_lst\n","            pred_sim_sort = sorted(pred_sim_lst, key=lambda x: x[1], reverse=False)\n","\n","            pred_final_op_lst = []\n","            for val, msr in pred_sim_sort:\n","                if(msr<threshold and len(pred_final_op_lst)<db_param[\"op_k\"]):\n","                    pred_final_op_lst.append(val)\n","\n","            join_str=join_str_cnst\n","            if(len(pred_final_op_lst)>0):\n","                tmp_op = {\"entity1\": \"\", \"entity2\": \"\", \"measure\": \"\"}\n","                tmp_op['entity1'] = trgt_key\n","                tmp_op['entity2'] = join_str.join(pred_final_op_lst)\n","                tmp_op['measure'] = 1.0\n","                final_op.append(tmp_op)\n","\n","        saveFinalOP(final_op, conf, db_param)\n","        time.sleep(wait_time)\n","\n","    except Exception as exp:\n","        raise exp\n","    finally:\n","        print(\"#################### OntoEvaluation FINISH ####################\")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJIjPktdS0gP","executionInfo":{"status":"ok","timestamp":1617588801167,"user_tz":420,"elapsed":88861,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}}},"source":["def ontoEvalCS(db_param):\n","\n","    try:\n","        print(\"#################### OntoEvaluation START ####################\")\n","\n","        conf = assignVar()\n","\n","        word_sim_info = None\n","        meta_sim_info = None\n","        if (db_param[\"sim_ind\"] == word_sim_ind_1):  # word_sim_ind_1 = \"cosine\"\n","            word_sim_info = loadData(conf[\"ws_fl_nm\"] + \"word_sim/word_sim_cosine.json\")\n","            meta_sim_info = loadData(conf[\"ws_fl_nm\"] + \"meta_sim/meta_sim_cosine.json\")\n","        elif (db_param[\"sim_ind\"] == word_sim_ind_2):  # word_sim_ind_2 = \"euclidean\"\n","            word_sim_info = loadData(conf[\"ws_fl_nm\"] + \"word_sim/word_sim_euclidean.json\")\n","            meta_sim_info = loadData(conf[\"ws_fl_nm\"] + \"meta_sim/meta_sim_euclidean.json\")\n","\n","\n","        word_wt = 0.5\n","        meta_wt = 0.5\n","        threshold = 0.0\n","        if (db_param[\"db_nm\"] == ds_nm_1):\n","            word_wt = db_param[\"word_wt_ds\"]\n","            meta_wt = db_param[\"meta_wt_ds\"]\n","            threshold = db_param[\"threshold_ds\"]\n","\n","        final_op = []\n","        for trgt_key in word_sim_info:\n","\n","            word_sim_lst = [[key, sim] for key, sim in word_sim_info[trgt_key].items()]\n","            meta_sim_lst = [[key, sim] for key, sim in meta_sim_info[trgt_key].items()]\n","\n","            word_sim_lst_modf, meta_sim_lst_modf = modifyWsMs(word_sim_lst, meta_sim_lst)\n","            pred_sim_lst = []\n","            for idx, word_sim in enumerate(word_sim_lst_modf):\n","                word_sim_key, word_sim_val = word_sim[0], word_sim[1]\n","                if (word_sim_val == 0):\n","                    pred_sim_lst = word_sim_lst\n","                    break\n","                else:\n","                    for m_key, m_val in meta_sim_lst_modf:\n","                        if(m_key == word_sim_key):\n","                            new_sim_val = word_wt * word_sim_val + meta_wt * m_val\n","                            pred_sim_lst.append([word_sim_key, new_sim_val])\n","\n","            pred_sim_sort = sorted(pred_sim_lst, key=lambda x: x[1], reverse=False)\n","\n","            pred_final_op_lst = []\n","            for val, msr in pred_sim_sort:\n","                if(msr<threshold and len(pred_final_op_lst)<db_param[\"op_k\"]):\n","                    pred_final_op_lst.append(val)\n","\n","            join_str=join_str_cnst\n","            if(len(pred_final_op_lst)>0):\n","                tmp_op = {\"entity1\": \"\", \"entity2\": \"\", \"measure\": \"\"}\n","                tmp_op['entity1'] = trgt_key\n","                tmp_op['entity2'] = join_str.join(pred_final_op_lst)\n","                tmp_op['measure'] = 1.0\n","                final_op.append(tmp_op)\n","\n","        saveFinalOP(final_op, conf, db_param)\n","        time.sleep(wait_time)\n","\n","    except Exception as exp:\n","        raise exp\n","    finally:\n","        print(\"#################### OntoEvaluation FINISH ####################\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"xV3KfWzFV6Gh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617589282582,"user_tz":420,"elapsed":570270,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}},"outputId":"4ea7d1e0-2d62-401e-fc2e-2b15043e1fed"},"source":["# ////// VECTOR-DIMENSION START //////\n","# // int vec_dim = 100;\n","# //int vec_dim = 200;\n","# // int vec_dim = 300;\n","# ////// VECTOR-DIMENSION END //////\n","\n","# ////// TEST PARAMETER START //////\n","# //int op_k=5;\n","# //int op_k=3;\n","# //int op_k=1;\n","\n","# //////For Anatomy dataset (distance | similarity)\n","# // double threshold_ds = 0.01; //0.99\n","# // double threshold_ds = 0.02; //0.98\n","# // double threshold_ds = 0.03; //0.97\n","# // double threshold_ds = 0.04; //0.96\n","# // double threshold_ds = 0.05; //0.95\n","# // double threshold_ds = 0.06; //0.94\n","# // double threshold_ds = 0.07; //0.93\n","# // double threshold_ds = 0.08; //0.92\n","# // double threshold_ds = 0.09; //0.91\n","# // double threshold_ds = 0.10; //0.90\n","# // double threshold_ds = 0.15; //0.85\n","# // double threshold_ds = 0.20; //0.80\n","# // double threshold_ds = 0.25; //0.75\n","# // double threshold_ds = 0.30; //0.70\n","# // double threshold_ds = 0.35; //0.65\n","# // double threshold_ds = 0.40; //0.60\n","# // double threshold_ds = 0.45; //0.55\n","# // double threshold_ds = 0.50; //0.50\n","# // double threshold_ds = 0.55; //0.45\n","# // double threshold_ds = 0.60; //0.40\n","# //double threshold_ds = 0.65; //0.35\n","# // double threshold_ds = 0.70; //0.30\n","# // double threshold_ds = 0.75; //0.25\n","# // double threshold_ds = 0.80; //0.20\n","# // double threshold_ds = 0.85; //0.15\n","# // double threshold_ds = 0.90; //0.10\n","# // double threshold_ds = 0.95; //0.05\n","# // double threshold_ds = 1.00; //0.00\n","# ////// TEST PARAMETER START //////\n","\n","\n","if __name__==\"__main__\":\n","  # data_param = getDataParam()\n","  db_param = {\n","      'db_nm' : 'Anatomy',\n","      \"vec_dim\": 200,\n","      'op_k' : 1,\n","      'word_wt_ds' : 0.5,\n","      'meta_wt_ds' : 0.5,\n","      'threshold_ds' : 0.02,\n","      \"sim_ind\": \"cosine\", #euclidean\n","      \"op_fl\": \"\"\n","  }\n","  # ontoEval(db_param)\n","  op_ks=[1,3,5]\n","  threshold_dss=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10]\n","  for op_k in op_ks:\n","    for threshold_ds in threshold_dss:\n","      db_param[\"op_k\"] = op_k\n","      db_param[\"threshold_ds\"] = threshold_ds\n","      sim=int((1-threshold_ds)*100)\n","      fl_nm=str(op_k) + \"_\" + str(sim) + \"_output_final.json\" \n","      db_param[\"op_fl\"] = DATA_DIR+'/output/' + fl_nm\n","      ontoEvalMS(word_sim_ind_1, db_param)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n","#################### OntoEvaluation START ####################\n","#################### OntoEvaluation FINISH ####################\n"],"name":"stdout"}]}]}