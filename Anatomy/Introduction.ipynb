{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMlVexzvq1WBEdvxZm8mafo"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ioTfd_HPQeLB"},"source":["<h1>\n","  <b>\n","    OntoConnect with Graph Neural Network (pytorch - biggraph)\n","  </b>\n","</h1>"]},{"cell_type":"markdown","metadata":{"id":"SjBS9SXnQxVB"},"source":["<ul>\n","<li>Input:\n","  <ul>\n","    <li> source.json (Human) </li>\n","    <li> target.json (Mouse) </li>\n","  </ul>\n","</li>\n","<li>Output:\n","  <ul>\n","    <li> alignment </li>\n","  </ul>\n","</ul>"]},{"cell_type":"markdown","metadata":{"id":"Bit3ZdeRz3ut"},"source":["<h2> Model Info: </h2>\n","\n","<ol>\n","<li>\n","PyTorch-BigGraph (PBG) is released by Facebook’s research team\n","</li>\n","<li>\n","Graph embedding methods learn a vector representation of each node in a graph by optimizing the objective that the embeddings for pairs of nodes with edges between them are closer together than pairs of nodes without a shared edge.\n","</li>\n","<li>\n","Graph embedding methods are a form of unsupervised learning, in that they learn representations of nodes using only the graph structure and no task-specific “labels” for nodes.\n","</li>\n","<li>\n","Working Principle\n","  <ol>\n","      <li>\n","        List of edges\n","        <table>\n","          <tr>\n","            <td>\n","              <table>\n","                <tr>\n","                  <td> SOURCE </td>\n","                  <td> EDGE </td>\n","                  <td> DESTINATION </td>\n","                </tr>\n","                <tr>\n","                  <td> \"http://human.owl#NCI_C41452\" </td>\n","                  <td> \"self\" </td>\n","                  <td> \"http://human.owl#NCI_C41452\" </td>\n","                </tr>\n","                <tr>\n","                  <td> \"http://human.owl#NCI_C41452\" </td>\n","                  <td> \"parent\" </td>\n","                  <td> \"http://human.owl#NCI_C22921\" </td>\n","                </tr>\n","                <tr>\n","                  <td> \"http://human.owl#NCI_C41452\" </td>\n","                  <td> \"child\" </td>\n","                  <td> \"http://human.owl#NCI_C13003\" </td>\n","                </tr>\n","                <tr>\n","                  <td> \"http://human.owl#NCI_C41452\" </td>\n","                  <td> \"child\" </td>\n","                  <td> \"http://human.owl#NCI_C19526\" </td>\n","                </tr>\n","                <tr>\n","                  <td> \"http://human.owl#NCI_C41452\" </td>\n","                  <td> \"eq\" </td>\n","                  <td> \"http://human.owl#NCI_C12928\" </td>\n","                </tr>\n","                <tr>\n","                  <td> \"http://human.owl#NCI_C41452\" </td>\n","                  <td> \"disjoint\" </td>\n","                  <td> \"http://human.owl#NCI_C41448\" </td>\n","                </tr>\n","                <tr>\n","                  <td> \"http://human.owl#NCI_C41452\" </td>\n","                  <td> \"restriction\" </td>\n","                  <td> \"http://human.owl#NCI_C41623\" </td>\n","                </tr>\n","              </table>\n","            </td>\n","            <td>\n","                <table>\n","                  <tr>\n","                  <td colspan=3>\n","                  <img src='https://drive.google.com/uc?export=view&id=10Tg2CxvbX-sgemDjXxAiAXa25Ai8pdwS' width='600' height='300'/> \n","                  </td>\n","                </tr>\n","                </table>\n","            </td>\n","          </tr>\n","        </table>\n","      </li>\n","      <li>\n","        Initial Node Embedding (generated from FastText)\n","        <table>\n","          <tr>\n","            <td> Node </td>\n","            <td> 100d/200d/300d vectors </td>\n","          </tr>\n","          <tr>\n","            <td> http://human.owl#NCI_C41452 </td>\n","            <td> [, , , , ..] </td>\n","          </tr>\n","          <tr>\n","            <td> ... </td>\n","            <td> ... </td>\n","          </tr>\n","        </table>\n","      </li>\n","      <li>\n","        The main idea of training the Graph embeddings\n","        <ol>\n","            <li>\n","              The edges provided in dataset are considered as positive edges.\n","            </li>\n","            <li>\n","              It generates negative edges between the nodes which are not connected. These random “false” edges as negative training examples along with the true positive edges.\n","            </li>\n","            <li>\n","              Idea is maximize the score of positive edges and minimize the score of negative edges.\n","            </li>\n","        </ol>\n","      </li>\n","  </ol>\n","</li>\n","</ol>\n","\n","The <b>score function</b> is as follows \\\\\n","$ f(\\theta_s, \\theta_r, \\theta_d) = \n","sim(g_{s}(\\theta_s, \\theta_r), g_{d}(\\theta_d, \\theta_r))$ \\\\\n","sim is cos/dot/l2 \\\\\n","$g_{(s/d)}$ is operator ~ none/translation/diagonal/linear/affine/complex-diagonal \\\\\n","\n","The <b>loss function</b> is as follows \\\\\n","$ \\mathcal{L} = \\sum_{e \\in G} \\sum_{e' \\in S'_{e}} max( f(e) - f(e') + \\lambda, 0) $ \\\\\n","$G$ id list of edges \\\\\n","$S'_{e}$ set of negative edges for every positive edge \\\\\n","$f(e)$ score for a positive edge \\\\\n","$f(e')$ score for a negative edge \\\\\n","$\\lambda$ is regularization"]},{"cell_type":"markdown","metadata":{"id":"eYWl8aMSbMxl"},"source":["<h2> Step-1 ~ ModifyLbl.ipynb</h2>\n","\n","[Modify Labels](https://colab.research.google.com/drive/1c4NwIZww27Fg3bcbtlCOVSyPBLl7efpM)\n","\n","---\n","\n","<ul>\n","<li> read the input files\n","  <ul>\n","      <li> /ip/source.json </li>\n","      <li> /ip/target.json </li>\n","  </ul>\n","</li>\n","<li> convert the \"lbl\" and populate \"altLbl\" </li>\n","<li> save the output files\n","  <ul>\n","      <li> /modifylbl/source.json </li>\n","      <li> /modifylbl/target.json </li>\n","  </ul>\n","</li>\n","</ul>\n","\n","\n","```json\n","\"http://human.owl#NCI_C41452\": {\n","        \"lbl\": \" Subependymal_Cell\",\n","        \"altLbl\": \"cell subependymal\",\n","        \"iri\": \"http://human.owl#NCI_C41452\",\n","        \"vector\": null,\n","        \"entityTyp\": \"Class\",\n","        \"parentCls\": [\n","            \"http://human.owl#NCI_C13003\"\n","        ],\n","        \"childCls\": [],\n","        \"eqCls\": [],\n","        \"disjointCls\": [],\n","        \"restriction\": [\n","            \"(<http://human.owl#UNDEFINED_part_of>,http://human.owl#NCI_C41448)\",\n","            \"(<http://human.owl#UNDEFINED_part_of>,http://human.owl#NCI_C41623)\"\n","        ]\n","    }\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uM4tXJ0rrYUN"},"source":["<h2> Step-2 ~ CreateDictionary.ipynb </h2>\n","\n","[Create Dictionary](https://colab.research.google.com/drive/1zaJ9NI7S_zauaN_aGR6gBC0H0qJcMRKx)\n","\n","---\n","\n","<ul>\n","<li> read the input files </li>\n","  <ul>\n","      <li> /modifylbl/source.json </li>\n","      <li> /modifylbl/source.json </li>\n","  </ul>\n","  <li> create dictionary of all words present in the all entities. </li>\n","  <ul>\n","      <li> No of Unique Words:- 2124 </li>\n","  </ul>\n","<li> save the output files </li>\n","  <ul>\n","      <li> /dict/dict.txt </li>\n","  </ul>\n","</ul>"]},{"cell_type":"markdown","metadata":{"id":"EMspc8rXAWeq"},"source":["<h2> Step-3 ~ DictionaryToVector.ipynb </h2>\n","\n","[Dictionary To Vector](https://colab.research.google.com/drive/1OG38pTjq2g_O89VLJhogkC8JC5RNMYqe)\n","\n","---\n","\n","<ul>\n","<li> read the dictionary file </li>\n","  <ul>\n","      <li> /dict/dict.txt </li>\n","  </ul>\n","<li> Get the FastText vector for each dictionary word. </li>\n","<li> save the output file with vectors </li>\n","  <ul>\n","      <li> /dict/dict.json </li>\n","  </ul>\n","</ul>"]},{"cell_type":"markdown","metadata":{"id":"ijIxc2_lA_M7"},"source":["<h2> Step-4 ~ EntityToVector.ipynb </h2>\n","\n","[Entity To Vector](https://colab.research.google.com/drive/1SwffXceB8PkSu15WUY2ZxOSHvND0djV_)\n","\n","---\n","\n","<ul>\n","<li> read the dictionary file </li>\n","  <ul>\n","      <li> /dict/dict.json </li>\n","      <li> /modifylbl/source.json </li>\n","      <li> /modifylbl/target.json </li>\n","  </ul>\n","<li> copy the vectorsint the source and target file </li>\n","<li> save the output file with vectors </li>\n","  <ul>\n","      <li> /fastentity/source_fast.json </li>\n","      <li> /fastentity/target_fast.json </li>\n","  </ul>\n","</ul>"]},{"cell_type":"markdown","metadata":{"id":"5TNzRUUu7XkX"},"source":["<h2> Step-5 ~ GenWordSim.ipynb </h2>\n","\n","[Generate Word Similarity](https://colab.research.google.com/drive/1l_8iOytPoh4k0D0T6XCY-tybXI7WC8mB)\n","\n","---\n","\n","<ul>\n","<li> read the vectors for both the source and target </li>\n","  <ul>\n","      <li> /fastentity/source_fast.json </li>\n","      <li> /fastentity/target_fast.json </li>\n","  </ul>\n","<li> create a json file that contains top-k similar human entities for each mouse entity</li>\n","  <ul>\n","      <li> /output/word_sim/word_sim_cosine.json </li>\n","  </ul>\n","</ul>\n","\n","***\n","```json\n","{\n","    \"http://mouse.owl#MA_0001080\": {\n","        \"http://human.owl#NCI_C32243\": 0.20560630681970293,\n","        \"http://human.owl#NCI_C33727\": 0.20639166686063304,\n","        \"http://human.owl#NCI_C33502\": 0.21291418700858478,\n","        \"http://human.owl#NCI_C32903\": 0.2141350602468982,\n","        \"http://human.owl#NCI_C12719\": 0.2657356704378381\n","}\n","```\n","***"]},{"cell_type":"markdown","metadata":{"id":"AvIv80lMw3qN"},"source":["<h2> Step-6 ~ GenerateGraphData.ipynb </h2>\n","\n","[Generate Graph Data](https://colab.research.google.com/drive/1Rya3lelqcC5MRM6w0K-_WS53_zjz3TTK)\n","\n","---\n","\n","<ul>\n","<li> read the structures for both the source and target </li>\n","  <ul>\n","      <li> /fastentity/source_fast.json </li>\n","      <li> /fastentity/target_fast.json </li>\n","  </ul>\n","<li> generate edges for for both source and target</li>\n","  <ul>\n","      <li> /gnnentity/source_gnn.json </li>\n","      <li> /gnnentity/target_gnn.json </li>\n","  </ul>\n","</ul>\n","\n","***\n","```json\n","\"http://human.owl#NCI_C41452\": {\n","\"graphEdges\": [\n","            [\"http://human.owl#NCI_C41452\", \"self\", \"http://human.owl#NCI_C41452\"],\n","            [\"http://human.owl#NCI_C41452\", \"parent\", \"http://human.owl#NCI_C13003\"],\n","            [\"http://human.owl#NCI_C13003\", \"parent\", \"http://human.owl#NCI_C41452\"]\n","            [\"http://human.owl#NCI_C41452\", \"restriction\", \"http://human.owl#NCI_C41448\"],\n","            [\"http://human.owl#NCI_C41448\", \"restriction\", \"http://human.owl#NCI_C41452\"],\n","            [\"http://human.owl#NCI_C41452\", \"restriction\",\"http://human.owl#NCI_C41623\"],\n","            [\"http://human.owl#NCI_C41623\", \"restriction\",\"http://human.owl#NCI_C41452\"]\n","        ]\n","}\n","```\n","***"]},{"cell_type":"markdown","metadata":{"id":"eHDlYV3exCHd"},"source":["<h2> Step-7 ~ EmbedOntoGraph.ipynb </h2>\n","\n","[Embed Onto Graph](https://colab.research.google.com/drive/1mx_bnqXk6ZNGlNaFHs0Gh3BXOtjaMl6R)\n","\n","---\n","\n","<ul>\n","<li> \n","  read both the source and target one by one\n","  <ul>\n","    <li> fastentity/source_fast.json </li>\n","    <li> fastentity/target_fast.json </li>\n","  </ul>\n","</li>\n","<li> Now for each entity in source/target file \n","  <ul>\n","    <li> \n","      extract the enitity name ~ NCI_C41452 \n","    </li>\n","    <li> \n","      get the updated embedding\n","        <ul>\n","          <li>\n","            first, it creates all the necessary files for the training \n","            <ul>\n","              <li> /gnnentity/entity_graph/src/[entity_nm]/graphs/ </li>\n","            </ul>\n","          </li>\n","          <li>\n","            populate pre-embeddings (FastText) in the h5py file\n","          </li>\n","          <li>\n","            train each graph (entity) with num_epochs (100)\n","          </li>\n","          <li>\n","             retrieve the new embedding\n","          </li>\n","        </ul>\n","    </li>\n","    <li> \n","      store the new embedding it in dictionary for each entity\n","    </li>\n","  </ul>\n","</li>\n","<li> store the dictionary in a new file, this will contain the new embedding for each entity both for source and target\n","  <ul>\n","    <li> /gnnentity/source_gnn_meta.json </li>\n","    <li> /gnnentity/target_gnn_meta.json </li>\n","  </ul>\n","</ul>\n","</li>"]},{"cell_type":"markdown","metadata":{"id":"GJqIuDhCCN37"},"source":["<h2> Step-8 ~ GenMetaSim.ipynb </h2>\n","\n","[GenMetaSim](https://colab.research.google.com/drive/1QzgpuX0Sutc6JYxcYoHfggjCJFcK78cz)\n","\n","---\n","\n","<ul>\n","<li> read the vectors for both the source and target </li>\n","  <ul>\n","      <li> /gnnentity/source_gnn_meta.json </li>\n","      <li> /gnnentity/target_gnn_meta.json </li>\n","  </ul>\n","<li> create a json file that contains top-k (same as word-sim) similar human entities for each mouse entity</li>\n","  <ul>\n","      <li> /output/meta_sim/meta_sim_cosine.json </li>\n","  </ul>\n","</ul>\n","\n","***\n","```json\n","{\n","    \"http://mouse.owl#MA_0001080\": {\n","        \"http://human.owl#NCI_C32243\": 0.20560630681970293,\n","        \"http://human.owl#NCI_C33727\": 0.20639166686063304,\n","        \"http://human.owl#NCI_C33502\": 0.21291418700858478,\n","        \"http://human.owl#NCI_C32903\": 0.2141350602468982,\n","        \"http://human.owl#NCI_C12719\": 0.2657356704378381\n","    }\n","}\n","```\n","***"]},{"cell_type":"markdown","metadata":{"id":"9vTYGd7c-4am"},"source":["<h2> Step-9 ~ GenCombSim.ipynb </h2>\n","\n","[Generate Combine Similarity](https://colab.research.google.com/drive/1gIiCL-Q0AhturkStQURgD0CZgo_ntaMV)\n","\n","<ul>\n","<li> read the vectors for both the source and target </li>\n","  <ul>\n","      <li> /output/word_sim/word_sim_cosine.json </li>\n","      <li> /output/meta_sim/meta_sim_cosine.json </li>\n","  </ul>\n","<li> create a json file that contains top-k similar human entities for each mouse entity</li>\n","  <ul>\n","      <li> /output/output_final.json</li>\n","  </ul>\n","</ul>\n","\n","***\n","```json\n","[\n","   {\n","        \"entity1\": \"http://mouse.owl#MA_0001087\",\n","        \"entity2\": \"http://human.owl#NCI_C12665\",\n","        \"measure\": 1.0\n","   }\n","]\n","```\n","***"]},{"cell_type":"markdown","metadata":{"id":"WmN3O8BC_M1K"},"source":["<h2> Step-10 ~ OntoEvaluation.ipynb </h2>\n","\n","[Evaluation](https://colab.research.google.com/drive/1eou9zpCW7dLLMudoMwF5yfPBh6lbZ1_4)\n","\n","<ul>\n","<li> read the vectors for both the source and target\n","  <ul>\n","      <li> /gold_copy/reference.xml </li>\n","      <li> /output/output_final.json </li>\n","  </ul>\n","</li>\n","<li> It prints the precision, recall and F-measure</li>\n","</ul>\n","\n","***\n","```text\n","Precision: 0.935\n","Recall: 0.710\n","F measure: 0.807\n","```\n","***"]},{"cell_type":"code","metadata":{"id":"ga8hj5qS_bnL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YvUBbTjLOl-z"},"source":["<h2> Resources </h2>\n","\n","<ul>\n","<li>\n","<b>Main Paper: https://mlsys.org/Conferences/2019/doc/2019/71.pdf </b>\n","</li>\n","<li>\n","https://torchbiggraph.readthedocs.io/en/stable/data_model.html\n","</li>\n","<li>\n","https://torchbiggraph.readthedocs.io/en/latest/scoring.html#interpreting-the-scores\n","</li>\n","<li>\n","https://torchbiggraph.readthedocs.io/en/latest/faq_troubleshooting.html\n","</li>\n","<li>\n","https://github.com/facebookresearch/PyTorch-BigGraph\n","</li>\n","<li> https://github.com/facebookresearch/PyTorch-BigGraph/blob/master/docs/source/configuration_file.rst </li>\n","<li>http://pages.cs.wisc.edu/~shivaram/cs744-fa20-slides/cs744-pytorch-biggraph-notes.pdf</li>\n","<li>\n","https://ai.facebook.com/blog/open-sourcing-pytorch-biggraph-for-faster-embeddings-of-extremely-large-graphs\n","</li\n","</ul>"]},{"cell_type":"markdown","metadata":{"id":"00Az9AxgG64v"},"source":["<h2> CrtUtil.ipynb </h2>\n","\n","[Create Utility](https://colab.research.google.com/drive/1L3IUTTRk4Zx7G5tgz6Xzi-IZR1KSMKpo)\n","\n","<ul>\n","<li> create constant (OntoSimConstants.py) </li>\n","<li> create import (OntoSimImports.py)</li>\n","<li> create parameter file (ontosim.json)</li>\n","<li> create folders under data folder</li>\n","</ul>"]},{"cell_type":"markdown","metadata":{"id":"I29O8ak5H8QM"},"source":["<h2> Result Analysis </h2>\n","\n","\n","<table>\n","<tr>\n","  <td>|</td>\n","  <td>|</td>\n","  <td colspan=3> 100-dimension |</td>\n","  <td colspan=3> 200-dimension |</td>\n","  <td colspan=3> 300-dimension |</td>\n","</tr>\n","<tr> \n","<tr>\n","  <td> Number of Prediction |</td>\n","  <td> Similarity Threshold |</td>\n","  <td> Precision |</td>\n","  <td> Recall |</td>\n","  <td> F-measure |</td>\n","  <td> Precision |</td>\n","  <td> Recall |</td>\n","  <td> F-measure |</td>\n","  <td> Precision |</td>\n","  <td> Recall |</td>\n","  <td> F-measure</td>\n","</tr>\n","<tr>\n","  <td rowspan=10> Top-1 |</td>\n","  <td> 0.99 |</td>\n","  <td> 0.974 |</td>\n","  <td> 0.674 |</td>\n","  <td> 0.796 |</td>\n","  <td> 0.979 |</td>\n","  <td> 0.670 |</td>\n","  <td> 0.795 |</td>\n","  <td> 0.979 |</td>\n","  <td> 0.669 |</td>\n","  <td> 0.795  </td>\n","</tr>\n","<tr>\n","  <td> 0.98 |</td>\n","  <td> 0.935 |</td>\n","  <td> 0.710 |</td>\n","  <td> <b>0.807</b> |</td>\n","  <td> 0.967 |</td>\n","  <td> 0.692 |</td>\n","  <td> 0.806 |</td>\n","  <td> 0.973 |</td>\n","  <td> 0.683 |</td>\n","  <td> 0.803  </td>\n","</tr>\n","<tr>\n","  <td> 0.970 |</td>\n","  <td> 0.853 |</td>\n","  <td> 0.730 |</td>\n","  <td> 0.787 |</td>\n","  <td> 0.930 |</td>\n","  <td> 0.715 |</td>\n","  <td> <b>0.808</b> |</td>\n","  <td> 0.953 |</td>\n","  <td> 0.705 |</td>\n","  <td> <b>0.810</b>  </td>\n","</tr>\n","<tr>\n","  <td> 0.96 |</td>\n","  <td> 0.751 |</td>\n","  <td> 0.752 |</td>\n","  <td> 0.751 |</td>\n","  <td> 0.880 |</td>\n","  <td> 0.733 |</td>\n","  <td> 0.800 |</td>\n","  <td> 0.916 |</td>\n","  <td> 0.721 |</td>\n","  <td> 0.807  </td>\n","</tr>\n","<tr>\n","  <td> 0.95 |</td>\n","  <td> 0.678 |</td>\n","  <td> 0.766 |</td>\n","  <td> 0.719 |</td>\n","  <td> 0.808 |</td>\n","  <td> 0.750 |</td>\n","  <td> 0.777 |</td>\n","  <td> 0.868 |</td>\n","  <td> 0.736 |</td>\n","  <td> 0.797  </td>\n","</tr>\n","<tr>\n","  <td> 0.94 |</td>\n","  <td> 0.619 |</td>\n","  <td> 0.775 |</td>\n","  <td> 0.688 |</td>\n","  <td> 0.746 |</td>\n","  <td> 0.764 |</td>\n","  <td> 0.755 |</td>\n","  <td> 0.815 |</td>\n","  <td> 0.750 |</td>\n","  <td> 0.781  </td>\n","</tr>\n","<tr>\n","  <td> 0.93 |</td>\n","  <td> 0.578 |</td>\n","  <td> 0.786 |</td>\n","  <td> 0.666 |</td>\n","  <td> 0.692 |</td>\n","  <td> 0.773 |</td>\n","  <td> 0.730 |</td>\n","  <td> 0.754 |</td>\n","  <td> 0.764 |</td>\n","  <td> 0.759  </td>\n","</tr>\n","<tr>\n","  <td> 0.92 |</td>\n","  <td> 0.553 |</td>\n","  <td> 0.792 |</td>\n","  <td> 0.651 |</td>\n","  <td> 0.648 |</td>\n","  <td> 0.786 |</td>\n","  <td> 0.711 |</td>\n","  <td> 0.713 |</td>\n","  <td> 0.774 |</td>\n","  <td> 0.742  </td>\n","</tr>\n","<tr>\n","  <td> 0.91 |</td>\n","  <td> 0.532 |</td>\n","  <td> 0.804 |</td>\n","  <td> 0.641 |</td>\n","  <td> 0.612 |</td>\n","  <td> 0.794 |</td>\n","  <td> 0.690 |</td>\n","  <td> 0.671 |</td>\n","  <td> 0.783 |</td>\n","  <td> 0.723  </td>\n","</tr>\n","<tr>\n","  <td> 0.90 |</td>\n","  <td> 0.512 |</td>\n","  <td> 0.810 |</td>\n","  <td> 0.628 |</td>\n","  <td> 0.581 |</td>\n","  <td> 0.801 |</td>\n","  <td> 0.673 |</td>\n","  <td> 0.641 |</td>\n","  <td> 0.789 |</td>\n","  <td> 0.708  </td>\n","</tr>\n","<tr>\n","  <td colspan=11> </td>\n","</tr>\n","<tr>\n","  <td rowspan=10> Top-3 |</td>\n","  <td> 0.99 |</td>\n","  <td> 0.976 |</td>\n","  <td> 0.676 |</td>\n","  <td> 0.799 |</td>\n","  <td> 0.981 |</td>\n","  <td> 0.671 |</td>\n","  <td> 0.797 |</td>\n","  <td> 0.982 |</td>\n","  <td> 0.671 |</td>\n","  <td> 0.797  </td>\n","</tr>\n","<tr>\n","  <td> 0.98 |</td>\n","  <td> 0.940 |</td>\n","  <td> 0.714 |</td>\n","  <td> <b>0.811</b> |</td>\n","  <td> 0.969 |</td>\n","  <td> 0.693 |</td>\n","  <td> 0.808 |</td>\n","  <td> 0.976 |</td>\n","  <td> 0.685 |</td>\n","  <td> 0.805  </td>\n","</tr>\n","<tr>\n","  <td> 0.97 |</td>\n","  <td> 0.862 |</td>\n","  <td> 0.737 |</td>\n","  <td> 0.795 |</td>\n","  <td> 0.934 |</td>\n","  <td> 0.718 |</td>\n","  <td> <b>0.812</b> |</td>\n","  <td> 0.956 |</td>\n","  <td> 0.706 |</td>\n","  <td> <b>0.812</b>  </td>\n","</tr>\n","<tr>\n","  <td> 0.96 |</td>\n","  <td> 0.764 |</td>\n","  <td> 0.765 |</td>\n","  <td> 0.766 |</td>\n","  <td> 0.885 |</td>\n","  <td> 0.737 |</td>\n","  <td> 0.805 |</td>\n","  <td> 0.920 |</td>\n","  <td> 0.724 |</td>\n","  <td> 0.810  </td>\n","</tr>\n","<tr>\n","  <td> 0.95 |</td>\n","  <td> 0.697 |</td>\n","  <td> 0.787 |</td>\n","  <td> 0.739 |</td>\n","  <td> 0.815 |</td>\n","  <td> 0.757 |</td>\n","  <td> 0.784 |</td>\n","  <td> 0.873 |</td>\n","  <td> 0.740 |</td>\n","  <td> 0.802  </td>\n","</tr>\n","<tr>\n","  <td> 0.94 |</td>\n","  <td> 0.637 |</td>\n","  <td> 0.799 |</td>\n","  <td> 0.709 |</td>\n","  <td> 0.758 |</td>\n","  <td> 0.776 |</td>\n","  <td> 0.767 |</td>\n","  <td> 0.821 |</td>\n","  <td> 0.756 |</td>\n","  <td> 0.787  </td>\n","</tr>\n","<tr>\n","  <td> 0.93 |</td>\n","  <td> 0.598 |</td>\n","  <td> 0.813 |</td>\n","  <td> 0.689 |</td>\n","  <td> 0.707 |</td>\n","  <td> 0.790 |</td>\n","  <td> 0.746 |</td>\n","  <td> 0.764 |</td>\n","  <td> 0.774 |</td>\n","  <td> 0.769  </td>\n","</tr>\n","<tr>\n","  <td> 0.92 |</td>\n","  <td> 0.574 |</td>\n","  <td> 0.822 |</td>\n","  <td> 0.676 |</td>\n","  <td> 0.665 |</td>\n","  <td> 0.807 |</td>\n","  <td> 0.729 |</td>\n","  <td> 0.725 |</td>\n","  <td> 0.787 |</td>\n","  <td> 0.755  </td>\n","</tr>\n","<tr>\n","  <td> 0.91 |</td>\n","  <td> 0.554 |</td>\n","  <td> 0.836 |</td>\n","  <td> 0.667 |</td>\n","  <td> 0.628 |</td>\n","  <td> 0.816 |</td>\n","  <td> 0.709 |</td>\n","  <td> 0.687 |</td>\n","  <td> 0.802 |</td>\n","  <td> 0.740  </td>\n","</tr>\n","<tr>\n","  <td> 0.90 |</td>\n","  <td> 0.534 |</td>\n","  <td> 0.844 |</td>\n","  <td> 0.654 |</td>\n","  <td> 0.598 |</td>\n","  <td> 0.825 |</td>\n","  <td> 0.694 |</td>\n","  <td> 0.658 |</td>\n","  <td> 0.811 |</td>\n","  <td> 0.726  </td>\n","</tr>\n","<tr>\n","  <td colspan=11> </td>\n","</tr>\n","<tr>\n","  <td rowspan=10> Top-5 |</td>\n","  <td> 0.99 |</td>\n","  <td> 0.976 |</td>\n","  <td> 0.676 |</td>\n","  <td> 0.799 |</td>\n","  <td> 0.981 |</td>\n","  <td> 0.671 |</td>\n","  <td> 0.797 |</td>\n","  <td> 0.982 |</td>\n","  <td> 0.671 |</td>\n","  <td> 0.797  </td>\n","</tr>\n","<tr>\n","  <td> 0.98 |</td>\n","  <td> 0.940 |</td>\n","  <td> 0.714 |</td>\n","  <td> <b>0.811</b> |</td>\n","  <td> 0.969 |</td>\n","  <td> 0.693 |</td>\n","  <td> 0.808 |</td>\n","  <td> 0.976 |</td>\n","  <td> 0.685 |</td>\n","  <td> 0.805  </td>\n","</tr>\n","<tr>\n","  <td> 0.97 |</td>\n","  <td> 0.863 |</td>\n","  <td> 0.738 |</td>\n","  <td> 0.796 |</td>\n","  <td> 0.934 |</td>\n","  <td> 0.718 |</td>\n","  <td> <b>0.812</b> |</td>\n","  <td> 0.955 |</td>\n","  <td> 0.707 |</td>\n","  <td> <b>0.812</b>  </td>\n","</tr>\n","<tr>\n","  <td> 0.96 |</td>\n","  <td> 0.766 |</td>\n","  <td> 0.767 |</td>\n","  <td> 0.767 |</td>\n","  <td> 0.885 |</td>\n","  <td> 0.737 |</td>\n","  <td> 0.805 |</td>\n","  <td> 0.920 |</td>\n","  <td> 0.724 |</td>\n","  <td> 0.810  </td>\n","</tr>\n","<tr>\n","  <td> 0.95 |</td>\n","  <td> 0.699 |</td>\n","  <td> 0.790 |</td>\n","  <td> 0.742 |</td>\n","  <td> 0.815 |</td>\n","  <td> 0.757 |</td>\n","  <td> 0.784 |</td>\n","  <td> 0.873 |</td>\n","  <td> 0.740 |</td>\n","  <td> 0.802  </td>\n","</tr>\n","<tr>\n","  <td> 0.94 |</td>\n","  <td> 0.640 |</td>\n","  <td> 0.802 |</td>\n","  <td> 0.712 |</td>\n","  <td> 0.760 |</td>\n","  <td> 0.779 |</td>\n","  <td> 0.769 |</td>\n","  <td> 0.822 |</td>\n","  <td> 0.757 |</td>\n","  <td> 0.788  </td>\n","</tr>\n","<tr>\n","  <td> 0.93 |</td>\n","  <td> 0.603 |</td>\n","  <td> 0.820 |</td>\n","  <td> 0.695 |</td>\n","  <td> 0.709 |</td>\n","  <td> 0.793 |</td>\n","  <td> 0.749 |</td>\n","  <td> 0.766 |</td>\n","  <td> 0.776 |</td>\n","  <td> 0.771  </td>\n","</tr>\n","<tr>\n","  <td> 0.92 |</td>\n","  <td> 0.579 |</td>\n","  <td> 0.830 |</td>\n","  <td> 0.682 |</td>\n","  <td> 0.669 |</td>\n","  <td> 0.812 |</td>\n","  <td> 0.734 |</td>\n","  <td> 0.728 |</td>\n","  <td> 0.790 |</td>\n","  <td> 0.758  </td>\n","</tr>\n","<tr>\n","  <td> 0.91 |</td>\n","  <td> 0.562 |</td>\n","  <td> 0.848 |</td>\n","  <td> 0.676 |</td>\n","  <td> 0.632 |</td>\n","  <td> 0.821 |</td>\n","  <td> 0.714 |</td>\n","  <td> 0.690 |</td>\n","  <td> 0.805 |</td>\n","  <td> 0.743  </td>\n","</tr>\n","<tr>\n","  <td> 0.90 |</td>\n","  <td> 0.542 |</td>\n","  <td> 0.856 |</td>\n","  <td> 0.664 |</td>\n","  <td> 0.604 |</td>\n","  <td> 0.832 |</td>\n","  <td> 0.700 |</td>\n","  <td> 0.662 |</td>\n","  <td> 0.815 |</td>\n","  <td> 0.730  </td>\n","</tr>\n","</table>\n"]}]}