{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EmbedOntoGraph.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNdQAPc5TvnueuirQtSqLLo"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIJswtatz-eQ","executionInfo":{"status":"ok","timestamp":1613716124812,"user_tz":420,"elapsed":356,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}},"outputId":"4af1df58-3f8a-4777-bddf-305dd6cd7b51"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","DIR='/content/drive/MyDrive/Research/OntoConnectWithGNN/GNN_1/'\n","\n","import os\n","os.chdir(DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"P6S2da4Fw8DU","executionInfo":{"status":"ok","timestamp":1613716808998,"user_tz":420,"elapsed":64684,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}},"outputId":"2c63e43e-ec16-4ba8-90e9-15013222ce76"},"source":["from IPython.display import Javascript  # Restrict height of output cell.\n","display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))\n","\n","!python -c \"import torch; print(torch.__version__)\"\n","!python -c \"import torch; print(torch.version.cuda)\"\n","\n","!pip install git+https://github.com/facebookresearch/fastText.git\n","!pip install git+https://github.com/facebookresearch/PyTorch-BigGraph.git"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["google.colab.output.setIframeHeight(0, true, {maxHeight: 100})"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["1.7.0+cu101\n","10.1\n","Collecting git+https://github.com/facebookresearch/fastText.git\n","  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-25nrz16c\n","  Running command git clone -q https://github.com/facebookresearch/fastText.git /tmp/pip-req-build-25nrz16c\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (2.6.2)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (53.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (1.19.5)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3085023 sha256=759a032d54f23f310d652340925c67d4bf11f90d030eabf94464af0b4d4974c9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-aping052/wheels/69/f8/19/7f0ab407c078795bc9f86e1f6381349254f86fd7d229902355\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","Successfully installed fasttext-0.9.2\n","Collecting git+https://github.com/facebookresearch/PyTorch-BigGraph.git\n","  Cloning https://github.com/facebookresearch/PyTorch-BigGraph.git to /tmp/pip-req-build-ee51mvw7\n","  Running command git clone -q https://github.com/facebookresearch/PyTorch-BigGraph.git /tmp/pip-req-build-ee51mvw7\n","Requirement already satisfied (use --upgrade to upgrade): torchbiggraph==1.0.1.dev0 from git+https://github.com/facebookresearch/PyTorch-BigGraph.git in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: attrs>=18.2 in /usr/local/lib/python3.6/dist-packages (from torchbiggraph==1.0.1.dev0) (20.3.0)\n","Requirement already satisfied: h5py>=2.8 in /usr/local/lib/python3.6/dist-packages (from torchbiggraph==1.0.1.dev0) (2.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchbiggraph==1.0.1.dev0) (1.19.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from torchbiggraph==1.0.1.dev0) (53.0.0)\n","Requirement already satisfied: torch>=1 in /usr/local/lib/python3.6/dist-packages (from torchbiggraph==1.0.1.dev0) (1.7.0+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchbiggraph==1.0.1.dev0) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.8->torchbiggraph==1.0.1.dev0) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1->torchbiggraph==1.0.1.dev0) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1->torchbiggraph==1.0.1.dev0) (0.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1->torchbiggraph==1.0.1.dev0) (0.16.0)\n","Building wheels for collected packages: torchbiggraph\n","  Building wheel for torchbiggraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchbiggraph: filename=torchbiggraph-1.0.1.dev0-cp36-none-any.whl size=118720 sha256=2ccc9a0fcfdefed18dae9d80e87d90ccad4f6025fca9a31cf998b5f882cc535b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-u_kl7ac8/wheels/d5/d0/e8/9fa5ee999e79534d0c4cb2c9127e08cbf42ba9f1e701158a33\n","Successfully built torchbiggraph\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KI20ps_RwJ_H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613716815604,"user_tz":420,"elapsed":3486,"user":{"displayName":"Jaydeep Chakraborty","photoUrl":"","userId":"15937785283944377251"}},"outputId":"74635cee-43c7-4741-fdf9-30a51d976bdf"},"source":["#from OntoSimImports import *\n","%run OntoSimImports.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"78b3hbra02XL"},"source":["#import OntoSimConstants\n","%run OntoSimConstants.py\n","from OntoSimConstants import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vH6RVi0wybEg"},"source":["def assignVar():\n","\n","    conf = {\n","        \"conf_arr\": [\n","            {\n","                'ind' : 'source',\n","                'ent_fl_nm': DATA_DIR+'gnnentity/source_gnn.json',\n","                'intr_ent_fl_nm': DATA_DIR+'gnnentity/source_gnn_tmp.json', #intermediate file with timestamp ~ source_gnn_tmp.json\n","                'graph_fl_path': DATA_DIR+'gnnentity/entity_graph/',\n","                'op_embed_fl_nm': DATA_DIR+'gnnentity/source_gnn_meta.json'\n","            },\n","            {\n","                'ind' : 'target',\n","                'ent_fl_nm': DATA_DIR+'gnnentity/target_gnn.json',\n","                'intr_ent_fl_nm': DATA_DIR+'gnnentity/target_gnn_tmp.json', #intermediate file with timestamp ~ target_gnn_tmp.json\n","                'graph_fl_path': DATA_DIR+'gnnentity/entity_graph/',\n","                'op_embed_fl_nm': DATA_DIR+'gnnentity/target_gnn_meta.json'\n","            }\n","        ]\n","    }\n","\n","    return conf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEqCJTQAI6k-"},"source":["def getDataParam():\n","    data_param_fl_nm = code_path + data_param_json\n","    with open(data_param_fl_nm) as f:\n","        data_param = json.load(f)\n","    return data_param"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Y48lJHKM2MN"},"source":["def makeDir():\n","  fl_path=DATA_DIR+'gnnentity/entity_graph/'\n","  os.makedirs(fl_path, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oTkNCvoSBiRe"},"source":["def loadFile(fl_nm):\n","    with open(fl_nm) as f:\n","        data = json.load(f)\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bvy-6fE2QJRP"},"source":["def getRawConfig(init_path, graph_path, epochs, dim, lr_rate):\n","  raw_config = dict(\n","    # I/O data\n","    init_path=init_path,\n","    entity_path=graph_path,\n","    edge_paths=[\n","        graph_path + 'edges_partitioned/',\n","    ],\n","    # Graph structure\n","    entities={\n","        \"node\": {\"num_partitions\": 1}\n","    },\n","    relations=[\n","        {\n","            \"name\": \"self\",\n","            \"lhs\": \"node\",\n","            \"rhs\": \"node\",\n","            \"operator\": \"complex_diagonal\",\n","            \"weight\": 1.0\n","        },\n","        {\n","            \"name\": \"parent\",\n","            \"lhs\": \"node\",\n","            \"rhs\": \"node\",\n","            \"operator\": \"complex_diagonal\",\n","            \"weight\": 1.0\n","        },\n","        {\n","            \"name\": \"child\",\n","            \"lhs\": \"node\",\n","            \"rhs\": \"node\",\n","            \"operator\": \"complex_diagonal\",\n","            \"weight\": 1.0\n","        },\n","        {\n","            \"name\": \"equivalent\",\n","            \"lhs\": \"node\",\n","            \"rhs\": \"node\",\n","            \"operator\": \"complex_diagonal\",\n","            \"weight\": 1.0\n","        },\n","        {\n","            \"name\": \"disjoint\",\n","            \"lhs\": \"node\",\n","            \"rhs\": \"node\",\n","            \"operator\": \"complex_diagonal\",\n","            \"weight\": 1.0\n","        },\n","        {\n","            \"name\": \"restriction\",\n","            \"lhs\": \"node\",\n","            \"rhs\": \"node\",\n","            \"operator\": \"complex_diagonal\",\n","            \"weight\": 1.0\n","        }\n","    ],\n","    dynamic_relations=False,\n","    dimension=dim,  # output vector dimension of each node\n","    global_emb=False,\n","    comparator=\"dot\",\n","    checkpoint_path=graph_path + 'chkpt/',\n","    checkpoint_preservation_interval=100,\n","    num_epochs=epochs,\n","    num_uniform_negs=1000,\n","    loss_fn=\"ranking\",\n","    lr=lr_rate,\n","    regularization_coef=1e-3,\n","    eval_fraction=0.,\n","    verbose=0,\n","  )\n","\n","  return raw_config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRSZCyXJPsiD"},"source":["def populatePrimaryTrainFl(conf_val, data_param):\n","  graph_path=conf_val[\"graph_fl_path\"]\n","  graph_fl_nm=graph_path+'node_edge.tsv'\n","  raw_config=getRawConfig(\"\", graph_path, data_param[\"init_epoch\"], data_param[\"vec_dim\"], data_param[\"learning_rate\"])\n","  setup_logging()\n","  config = parse_config(raw_config)\n","  subprocess_init = SubprocessInitializer()\n","  input_edge_paths = [Path(graph_fl_nm)]\n","\n","  convert_input_data(\n","      config.entities,\n","      config.relations,\n","      config.entity_path,\n","      config.edge_paths,\n","      input_edge_paths,\n","      TSVEdgelistReader(lhs_col=0, rel_col=1, rhs_col=2),\n","      dynamic_relations=config.dynamic_relations,\n","  )\n","\n","  train(config, subprocess_init=subprocess_init)\n","\n","  return raw_config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZS4vy2d7ivks"},"source":["def addPreEmbedding(conf_val, NUMBER_OF_EPOCHS, raw_config, embeddings_dict):\n","  graph_path=conf_val[\"graph_fl_path\"]\n","  nodes_path = graph_path + 'entity_names_node_0.json'\n","  nodes_emb_path = graph_path + \"chkpt/\" + \"embeddings_node_0.v{NUMBER_OF_EPOCHS}.h5\".format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n","\n","  with open(nodes_path,'r') as source:\n","    nodes = json.load(source)\n","  dist = {item:ind for ind,item in enumerate(nodes)}\n","\n","  with h5py.File(nodes_emb_path,'r+') as source:\n","      for node in embeddings_dict:\n","        info=embeddings_dict[node]\n","        if node in nodes:\n","            source['embeddings'][dist[node]] = info['vector']\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOFvpCbNEB8l"},"source":["def populateNewEmbedding(conf_val, data_param):\n","  graph_path=conf_val[\"graph_fl_path\"]\n","  graph_fl_nm=graph_path+'node_edge.tsv'\n","  raw_config=getRawConfig(graph_path+\"chkpt/\", graph_path, data_param[\"total_epoch\"], data_param[\"vec_dim\"], data_param[\"learning_rate\"])\n","  setup_logging()\n","  config = parse_config(raw_config)\n","  subprocess_init = SubprocessInitializer()\n","  input_edge_paths = [Path(graph_fl_nm)]\n","\n","  convert_input_data(\n","      config.entities,\n","      config.relations,\n","      config.entity_path,\n","      config.edge_paths,\n","      input_edge_paths,\n","      TSVEdgelistReader(lhs_col=0, rel_col=1, rhs_col=2),\n","      dynamic_relations=config.dynamic_relations,\n","  )\n","\n","  train(config, subprocess_init=subprocess_init)\n","\n","  return raw_config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g_fhc9A0kO_a"},"source":["def getNewEmbedding(conf_val, NUMBER_OF_EPOCHS, raw_config, entity_obj):\n","  nodes_path = conf_val[\"graph_fl_path\"] + 'entity_names_node_0.json'\n","  nodes_emb_path = conf_val[\"graph_fl_path\"] + \"chkpt/\" + \"embeddings_node_0.v{NUMBER_OF_EPOCHS}.h5\".format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n","\n","  with open(nodes_path, 'r') as f:\n","      nodes = json.load(f)\n","\n","  with h5py.File(nodes_emb_path, 'r') as g:\n","      nodes_embeddings = g['embeddings'][:]\n","\n","  nodes2embedding = dict(zip(nodes, nodes_embeddings))\n","\n","  entity_id=entity_obj['iri']\n","\n","  return nodes2embedding[entity_id]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TsPEijWx7BLV"},"source":["def crtEdgeFl(conf_val, entity_obj):\n","  file_nm=conf_val['graph_fl_path']+'node_edge.tsv'\n","  with open(file_nm, 'w') as f:\n","    for edge in entity_obj['graphEdges']:\n","        f.write('\\t'.join(edge) + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MuSLCICr9oMf"},"source":["def delEdgeFl(conf_val):\n","  fl_path=conf_val['graph_fl_path']\n","  shutil.rmtree(fl_path)\n","  makeDir()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrpCiEvu1ZiR"},"source":["def trainNewEmbed(conf_val, entity_obj, data_param):\n","  \n","  crtEdgeFl(conf_val, entity_obj)\n","\n","  raw_config=populatePrimaryTrainFl(conf_val, data_param)\n","\n","  addPreEmbedding(conf_val, data_param[\"init_epoch\"], raw_config, entity_obj)\n","\n","  raw_config=populateNewEmbedding(conf_val, data_param)\n","\n","  embed=getNewEmbedding(conf_val, data_param[\"total_epoch\"], raw_config, entity_obj)\n","\n","  delEdgeFl(conf_val)\n","  \n","  return embed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HcOtTfEP03Jr"},"source":["def populateGNNEntityHelper(conf_val, entity_info, data_param):\n","  \n","  i=0\n","  if(conf_val['ind']=='source'):\n","    for src_entity in entity_info:\n","      entity_obj=entity_info[src_entity]\n","      if (entity_obj['metaVector']): #is not None then do nothing\n","        continue\n","      embed = trainNewEmbed(conf_val, entity_obj, data_param)\n","      entity_obj['metaVector'] = embed.tolist()\n","      entity_info[src_entity]=entity_obj\n","      if (i%data_param[\"save_intermediate_node\"] == 0):\n","        saveNewEmbeddingIntermediate(entity_info, DATA_DIR+'gnnentity/source_gnn_meta') #intermediate save \n","\n","      i=i+1\n","  elif(conf_val['ind']=='target'):\n","    for trgt_entity in entity_info:\n","      entity_obj=entity_info[trgt_entity]\n","      if (entity_obj['metaVector']): #is not None then do nothing\n","        continue\n","      embed = trainNewEmbed(conf_val, entity_obj, data_param) \n","      entity_obj['metaVector'] = embed.tolist()\n","      entity_info[trgt_entity]=entity_obj\n","      if (i%data_param[\"save_intermediate_node\"] == 0):\n","        saveNewEmbeddingIntermediate(entity_info, DATA_DIR+'gnnentity/target_gnn_meta') #intermediate save \n","\n","      i=i+1\n","  return entity_info"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GtxlTnOrSJUt"},"source":["def saveNewEmbeddingIntermediate(entity_info, fl):\n","    ct = datetime.datetime.now()\n","    ct = ct.strftime(\"%m_%d_%Y_%H_%M_%S\")\n","    fl_nm = fl+ct+'.json'\n","    with open(code_path+fl_nm, 'w') as outfile:\n","        json.dump(entity_info, outfile, indent=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o-MOhLeI496N"},"source":["def saveNewEmbedding(entity_info, conf):\n","    with open(code_path+conf['op_embed_fl_nm'], 'w') as outfile:\n","        json.dump(entity_info, outfile, indent=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jL65nmXpzGec"},"source":["def populateGNNEntity(data_param):\n","    try:\n","        print(\"#################### populateGNNEntity START ####################\")\n","        conf = assignVar()\n","        #####Mean of vectors\n","        conf_arr = conf[\"conf_arr\"]\n","        makeDir()\n","        for conf_val in conf_arr:\n","          if (data_param[\"prev_embed\"]==0):\n","            fl_nm = code_path+conf_val['ent_fl_nm']\n","            entity_info = loadFile(fl_nm)\n","          else:\n","            fl_nm = code_path+conf_val['intr_ent_fl_nm']\n","            entity_info = loadFile(fl_nm)\n","          \n","          entity_info=populateGNNEntityHelper(conf_val, entity_info, data_param)\n","          saveNewEmbedding(entity_info, conf_val) #final save \n","          time.sleep(wait_time)\n","\n","    except Exception as exp:\n","        raise exp\n","    finally:\n","        print(\"#################### populateGNNEntity FINISH ####################\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"13SitgNJOoCB"},"source":["from IPython.display import Javascript  # Restrict height of output cell.\n","display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","# 'prev_embed': 0, start from scratch or anything else  load previous embedding \n","# 'init_epoch' will be always 1 for creating initial file creation\n","# 'total_epoch' total epoch of training for each entity/node\n","\n","if __name__==\"__main__\":\n","  data_param = getDataParam()\n","  populateGNNEntity(data_param['model'])"],"execution_count":null,"outputs":[]}]}